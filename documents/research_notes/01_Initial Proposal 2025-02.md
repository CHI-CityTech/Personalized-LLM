# BBS-Personal-LLM

Personalized Large Language Model (LLM) Creation Project

Overview

Welcome to the official GitHub repository for the CHI Research Team's Personalized LLM Initiative, led by student researchers at City Tech. This project aims to design, evaluate, and deploy a lightweight, ethical, and scalable Large Language Model (LLM) tailored for real-time personalization across diverse domains—such as literature, STEM, and digital mediation within the Balanced Reality Platform System (BRPS).
Our mission is to build an open, responsible, and interdisciplinary AI framework that is transparent, adaptable, and aligned with human values.

Project Objectives

Evaluate existing commercial and open-source LLMs (e.g., ChatGPT, Claude, DeepSeek).
Design a custom AI system capable of interpreting multimodal inputs and adapting to individual users.
Implement real-time personalization based on behavior, history, and preferences.
Ensure data ethics and compliance with standards like GDPR and CCPA.
Benchmark and continuously optimize the model using feedback loops and RL fine-tuning.

Project Phases

1. Onboarding & Survey: Team setup, research review, initial LLM evaluations.
2. Requirements Analysis:	Define personalization levels, compliance boundaries, and data governance.
3. Model Selection & Training: Develop modular, scalable architecture with API integrations.
4. Model Implementation: Develop modular, scalable architecture with API integrations.
5. Testing & Validation: A/B testing, fairness audits, and ethical validations.
6. Deployment & Optimization:	Real-world deployment, KPI monitoring, and user-driven iteration.

Project Duration: Feb 23, 2025 – May 22, 2025 (Renewable)
Leads: Kazi Tasin (Lead), Kazi Rahimu Islam, Naureen Asha
Faculty Advisor: Prof. David Smith

Benchmarking Insights

We conducted a structured evaluation of three major LLMs—ChatGPT, Claude AI, and DeepSeek—by summarizing five articles from domains like economics, quantum computing, diplomacy, and digital realities.

Key Findings

Criteria                                                                      
Summarization                                      
Accuracy                                           
Analysis                                           
Hallucination

GPT  
Summarization: Strong synthesis, slight oversimplification
Accuracy: Minor omissions 
Analysis: Good, but shallow in complex topics 
Hallucination: Moderate risk 

Claude 
Summarization: Most accurate, structured summaries
Accuracy: Highly factual 
Analysis: Deep and contextual
Hallucination: Low 


DeepSeek
Summarization: Simplified, lacks political nuance
Accuracy: Avoids controversial topics
Analysis: Limited critical depth
Hallucination: Low but context-dependent

Claude AI outperformed others with its balanced, detailed, and context-aware summaries.
The evaluation was guided by criteria such as factual consistency, completeness, reasoning, and hallucination rate.

Tech Stack

Model Training: PyTorch, HuggingFace Transformers, LlamaCpp
Evaluation Framework: Custom rubric based on Error Rate (ER), Omission Rate (OR), and Alignment Score (AS)
Data Sources: Public articles (Forbes, Nvidia, USC, Webisoft, U.S. State Dept)
Version Control: GitHub, Zotero (Research logs)
Communication: Discord, BBS (Balanced Blended Space platform)

Ethical Commitment
We are committed to developing a fair, explainable, and user-consent-based AI system. 
Our LLM incorporates:

Transparent training data and logic.
Bias detection and fairness audits.
Privacy-by-design principles (anonymization, encryption, access control).
Alignment with legal standards (GDPR, CCPA).

Future Directions

Incorporate reinforcement learning with human feedback (RLHF) for adaptive responses.
Expand multimodal capabilities (image, sound, and mathematical problem processing).
Enable cross-platform AI agents for BRPS, education, and public services.
Launch a web-based interaction demo showcasing our personalized LLM.

Contact & Contributions

Interested in collaborating? Join us!

Prof. David Smith
Email: dsmith@citytech.cuny.edu

Student Researchers
Kazi Tasin: kazi.tasin@mail.citytech.cuny.edu
Kazi Islam: Kazi.Islam3@mail.citytech.cuny.edu







